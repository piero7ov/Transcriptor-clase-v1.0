# Transcriptor de Clase ğŸ§

AplicaciÃ³n web que captura audio del sistema o del micrÃ³fono y lo transcribe a texto en tiempo (casi) real usando **faster-whisper**.  
Pensado para tomar mejores apuntes durante clases, reuniones o vÃ­deos.

> Frontend sencillo en HTML/CSS/JS + backend en FastAPI (Python).

---

## âœ¨ CaracterÃ­sticas

- ğŸ™ï¸ Captura desde:
  - MicrÃ³fono
  - Audio del sistema (compartiendo audio en el navegador)
- â±ï¸ TranscripciÃ³n por *chunks* configurables (4 s, 6 s, 8 s, 10 sâ€¦)
- ğŸŒ“ Tema claro / oscuro (toggle en la interfaz)
- ğŸ§  Contexto de dominio configurable (glosario de tÃ©rminos tÃ©cnicos en el backend)
- ğŸ“‹ Botones Ãºtiles:
  - Iniciar / Detener / Pausarâ€“Reanudar
  - Copiar todo el texto al portapapeles
  - Limpiar la caja de transcripciÃ³n
- ğŸ’¾ Descarga de resultados:
  - TXT plano
  - SRT con marcas de tiempo
- ğŸŒ CORS preparado para funcionar con XAMPP u otros servidores locales (`http://localhost`, `http://127.0.0.1`)

---

## ğŸ—‚ Estructura del proyecto

```text
Transcriptor-clase-v1.0-main/
â”œâ”€â”€ README.md
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py               # API FastAPI (endpoints, carga de modelo, lÃ³gica FFmpeg)
â”‚   â”œâ”€â”€ chunk_buffer.py      # Buffer de segmentos y generaciÃ³n de TXT/SRT
â”‚   â”œâ”€â”€ requirements.txt     # Dependencias del backend
â”‚   â”œâ”€â”€ run_cpu.bat          # Script para lanzar en modo CPU (Windows)
â”‚   â””â”€â”€ .venv/               # Entorno virtual (puedes ignorarlo o recrearlo)
â”œâ”€â”€ fronted/
â”‚   â”œâ”€â”€ index.html           # Interfaz principal del transcriptor
â”‚   â”œâ”€â”€ style.css            # Estilos (incluye modo oscuro/claro)
â”‚   â””â”€â”€ app.js               # LÃ³gica de captura de audio y llamadas a la API
â””â”€â”€ documentaciÃ³n/
    â”œâ”€â”€ Manual_de_Usuario_Transcriptor.odt  # Manual de usuario
    â”œâ”€â”€ portada.png
    â””â”€â”€ portada2.png
````
---

## ğŸ§© TecnologÃ­as utilizadas

**Frontend**

* HTML5
* CSS3 (variables, tema claro/oscuro)
* JavaScript:

  * `getUserMedia` / `MediaRecorder` para capturar audio
  * `fetch` para enviar *chunks* al backend
  * Copiado al portapapeles, autoscroll, etc.

**Backend**

* [FastAPI](https://fastapi.tiangolo.com/)
* [faster-whisper](https://github.com/SYSTRAN/faster-whisper)
* `ffmpeg` y `ffprobe` vÃ­a `subprocess`
* `uvicorn` como servidor ASGI

---

## âœ… Requisitos previos

* **Python 3.10+** (recomendado)
* **FFmpeg** instalado y accesible en el `PATH`:

  * Comprobar con: `ffmpeg -version` y `ffprobe -version`
* Un navegador moderno (Chrome, Edge, Braveâ€¦) con soporte para:

  * Captura de pantalla/ventana/pestaÃ±a
  * Compartir audio del sistema (en caso de querer capturar el audio del PC)

Si quieres usar GPU:

* Tarjeta NVIDIA compatible
* Drivers + CUDA instalados (segÃºn requisitos de `faster-whisper`)

---

## âš™ï¸ ConfiguraciÃ³n del backend

1. Ve a la carpeta `backend`:

   ```bash
   cd backend
   ```

2. (Opcional pero recomendado) Crea y activa un entorno virtual:

   ```bash
   python -m venv .venv
   .venv\Scripts\activate   # En Windows
   # o
   source .venv/bin/activate  # En Linux/Mac
   ```

3. Instala las dependencias:

   ```bash
   pip install -r requirements.txt
   ```

4. El backend lee estas **variables de entorno**:

   ```text
   FW_MODEL   : small | medium | base    (por defecto: small)
   FW_DEVICE  : cuda | cpu               (por defecto: cuda)
   FW_CTYPE   : float16 | int8           (por defecto: float16 en GPU)
   ```

   Ejemplos:

   * Forzar CPU (lento pero sin GPU):

     ```bash
     set FW_MODEL=small
     set FW_DEVICE=cpu
     set FW_CTYPE=int8
     uvicorn app:app --reload --port 8000
     ```

     O simplemente usar el script incluido en Windows:

     ```bash
     run_cpu.bat
     ```

   * Usar GPU (si estÃ¡ disponible):

     ```bash
     set FW_MODEL=small
     set FW_DEVICE=cuda
     set FW_CTYPE=float16
     uvicorn app:app --reload --port 8000
     ```

5. Por defecto, el backend queda escuchando en:

   ```text
   http://127.0.0.1:8000
   ```

---

## ğŸ’» Puesta en marcha del frontend

1. Ve a la carpeta `fronted`:

   ```bash
   cd fronted
   ```

2. Opciones para servir el frontend:

   * Usar **XAMPP** (u otro servidor local) y colocar esta carpeta en `htdocs`.
   * Usar la extensiÃ³n **Live Server** (VS Code / similar).
   * O cualquier servidor estÃ¡tico sencillo.

3. Abre la pÃ¡gina en tu navegador:

   ```text
   http://localhost/.../fronted/index.html
   ```

AsegÃºrate de que la constante `API_BASE` de `app.js` apunta correctamente al backend:

```js
const API_BASE = "http://127.0.0.1:8000";
```

Si cambias el puerto o la IP, actualiza esta lÃ­nea.

---

## ğŸ§ª Uso bÃ¡sico

1. Abre el frontend (`index.html`).
2. Elige el origen:

   * **Audio del sistema** (compartir pestaÃ±a/ventana + marcar â€œCompartir audioâ€)
   * **MicrÃ³fono**
3. Ajusta el tamaÃ±o del *chunk* (por defecto 4 s).
4. Pulsa **â–¶ Iniciar**:

   * El navegador pedirÃ¡ permisos para capturar audio.
   * El backend irÃ¡ recibiendo *chunks* y actualizando la transcripciÃ³n.
5. Usa los controles:

   * â¸ **Pausar** / reanudar la captura
   * â–  **Detener** para terminar la sesiÃ³n
   * ğŸ“‹ **Copiar** para copiar todo el texto
   * ğŸ§¹ **Limpiar caja** para vaciar la transcripciÃ³n
6. Para descargar:

   * **TXT**: `http://127.0.0.1:8000/api/transcript.txt`
   * **SRT**: `http://127.0.0.1:8000/api/transcript.srt`

---

## ğŸ“¡ Endpoints principales (API)

| MÃ©todo | Ruta                  | DescripciÃ³n                                                 |
| ------ | --------------------- | ----------------------------------------------------------- |
| GET    | `/ping`               | ComprobaciÃ³n rÃ¡pida del backend (modelo, dispositivo, etc.) |
| GET    | `/api/reset`          | Reinicia la sesiÃ³n y borra el acumulado de audio            |
| POST   | `/api/chunk`          | Recibe un *chunk* de audio (`file`) y lo transcribe         |
| GET    | `/api/transcript.txt` | Devuelve la transcripciÃ³n completa en texto plano           |
| GET    | `/api/transcript.srt` | Devuelve la transcripciÃ³n completa en formato SRT           |

`/api/chunk` espera:

* `file`: audio (`.webm` o `.wav`) vÃ­a `multipart/form-data`
* `offset`: (opcional) inicio del *chunk* en segundos

La lÃ³gica del buffer y las marcas de tiempo estÃ¡ en `chunk_buffer.py`.

---

## ğŸ”§ ConfiguraciÃ³n del glosario / contexto

En `backend/app.py` hay una constante:

```python
PROMPT_EXTRA = (
    "informÃ¡tica hardware software placa base placas base buses de datos "
    "procesadores CPU GPU memoria RAM almacenamiento SSD disco duro SATA NVMe "
    "interfaces USB HDMI PCIe chipset BIOS UEFI audio digital analÃ³gico "
    "altavoces micrÃ³fono perifÃ©ricos teclado ratÃ³n monitor "
)
```

Puedes adaptarla a tu contexto de clase (derecho, medicina, logÃ­stica, etc.) para ayudar al modelo a entender mejor la terminologÃ­a de tu asignatura.

---

## ğŸ“„ DocumentaciÃ³n adicional

En la carpeta `documentaciÃ³n/` tienes:

* `Manual_de_Usuario_Transcriptor.odt`: manual detallado de uso.
* `portada.png`, `portada2.png`: recursos grÃ¡ficos para presentaciÃ³n o documentaciÃ³n.

---

## ğŸ‘¤ Autor

**Piero Olivares**

Proyecto creado para practicar captura de audio en navegador, FastAPI y transcripciÃ³n con modelos Whisper.

---
